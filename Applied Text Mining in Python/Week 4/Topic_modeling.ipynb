{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb33102-c386-458a-897a-f27a6404955b",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Topic Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f75c4-f962-467c-be0e-f7e20803ce47",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Semantic Text Similarity</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21124fc-4289-4ff2-9b4a-480c922760b6",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Semantic Similarity with WordNet</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            WordNet é um banco de palavras que busca agrupá-las de maneira hierárquica conforme a sua semântica.\n",
    "        </li>\n",
    "        <li> \n",
    "            A primeira maneira de medirmos a similaridade entre dois termos seria computando a sua distância em uma árvore de significados -Path Similarity. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03ea98-cb97-4bf6-9cab-580a7ed936e3",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Path Similarity</h4>\n",
    "<center> \n",
    "    <img src='path_similarity1.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            No caso da imagem, a distância é computada pelo número de passos que devem ser feitos entre os dois termos de interesse. Note que a distância entre palavras do mesmo grupo semântico, há uma distância de 1 (e não 2) passos!   \n",
    "        </li>\n",
    "        <li> \n",
    "            Path Similarity entre duas palavras (d=distância): $PathSim(p1, p2) = \\frac{1}{d(p1, p2)+1}$\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b577942a-61e8-46c6-8124-f35c9f7e5889",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Lowest Common Subsumer</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             O Lowest Common Subsumer entre duas expressões é o termo, dentro da hierarquia, que as engloba de maneira mais direta.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='lwst_subsumer.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Note que o Lowest Common Subsumer entre um termo e seu nó-pai é o próprio nó-pai.\n",
    "        </li>\n",
    "        <li> \n",
    "            A noção de LCS é utilizada na formulação de uma outra medida de similaridade, a Lin Similarity.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='linsim.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecdbed8f-febf-436a-8781-1ebd51305ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# O método 'synset' admite o nome do termo, a sua classe gramatical e a numeração do seu significado.   \n",
    "deer = wn.synset('deer.n.01')\n",
    "elk = wn.synset('elk.n.01')\n",
    "horse = wn.synset('horse.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c813f4-3bc5-499f-9805-ec3f2e2b1ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.125)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medindo a Path Similarity entre os termos listados.\n",
    "deer.path_similarity(elk), horse.path_similarity(elk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67eaaa-eacf-402a-b9b5-ae6d4fe1d333",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Use information criteria to find Lin Similarity</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51fc4806-800d-432a-a9d6-db9d882450dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7726998936065773, 0.8623778273893673)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "# Medindo a Lin Similarity.\n",
    "deer.lin_similarity(horse, brown_ic), deer.lin_similarity(elk, brown_ic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8983ae28-4f63-48da-b49e-147cfdd2ee74",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Collocations and Distributional Similarity</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Podemos explorar a similaridade entre termos conhecendo as palavras que os acompanham em frases.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='col_dist_sim1.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Observe que todas as palavras em vermelho ocorrem com o verbo \"meet\" e \"at\" ou \"the\".\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aca6e7-8b13-4f6a-bb36-ecee236ca0c0",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Distributional Similarity: Context</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Além dos termos acompanhantes em si, conseguimos utilizar classes gramaticais e sintáticas como base para a análise de similaridade.  \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829a03e-b9ab-432d-8ee2-73003fbea55b",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Strength of Association Between Words</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Palavras podem ser consideradas altamente relacionáveis caso elas ocorram juntas em muitos textos. No entanto, é preciso ter cuidado, pois expressões comuns como \"the\" e \"a\" costumam acompanhar diversas palavras do inglês.  \n",
    "        </li>\n",
    "        <li> \n",
    "            Considerando esse problema, foram elaboradas estratégias de normalização como a Pointwise Mutual Information.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b91e9-088c-4524-93c1-2fb80379b1f4",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src='collo1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ed3cd-d2c1-4bdf-92c1-1e813e71dbb9",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Topic Modeling</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6fc61-608d-4382-830c-51f72d188fb1",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Fazer um computador desvendar o tópico que um determinado texto aborda envolve fazê-lo identificar a frequência com que cada palavra ocorre no documento, já que ele não é capaz de extrair significados por conta própria.\n",
    "        </li>\n",
    "        <li> \n",
    "            Essa estratégia é conveniente pois palavras são selecionadas conforme o contexto em que o comunicador se encontra. Além disso, vale lembrar que modelos de classificação precisam de informações numéricas para que eles funcionem.\n",
    "        </li>\n",
    "        <li> \n",
    "            Muitas estratégias para modelagem de tópico existem, entre elas o LDA e PLSA.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237a366-e1c9-4715-bc0c-24149f6646d0",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Generative Models and LDA</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee5520-2b2d-4f9b-94eb-33f19f8ece89",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Generative Models são modelos que guardam a distribuição comum para textos de um determinado assunto. Se quiséssemos construir um texto de um computador, poderíamos consultar diversos Generative Models e extrair o seu vocabulário.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88cd88-b356-4e69-9429-7ae723dc0ae4",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> LDA</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            LDA é um modelo de geração de documentos que leva em consideração o comprimento do texto a ser criado e a quantidade de tópicos contidos nele. As palavras são lançadas ao documento respeitando a distribuição multinomial de cada assunto. \n",
    "        </li>\n",
    "        <li> \n",
    "            Pode ser usado em feature selection para tarefas de classificação textual.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913da9ff-0523-49ca-9954-241e1d19c67c",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Melhores Práticas em Generative Models</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tokenização e normalização. \n",
    "        </li>\n",
    "        <li> \n",
    "            Remoção de stop-words (the, a, an...)\n",
    "        </li>\n",
    "        <li> \n",
    "            Stemming, Lemmatization.\n",
    "        </li>\n",
    "        <li> \n",
    "            Montar uma document-matrix.\n",
    "        </li>\n",
    "        <li> \n",
    "            Criar um LDA sobre a document-matrix.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc527f8-d05c-4f55-af05-e5796988d2da",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src='lda1.png'> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f31b04-e131-42f9-9cbc-a243c90458d4",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Information Extraction</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158fa19-5b57-4b4c-8de2-fb53a8adb38f",
   "metadata": {},
   "source": [
    "<p style='color:red'>Information Extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
