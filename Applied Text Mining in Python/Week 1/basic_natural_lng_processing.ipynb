{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1fbef3-8ea0-44a6-9f70-5c161648f715",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Basic Natural Language Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6eb6e-fdc3-4f65-aeab-231e253e1028",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Basic NLP tasks with NLTK</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A biblioteca do NLTK possui um conjunto de textos-exemplo disponíveis para que o usuário treine as suas habilidades com NLP.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544d99a4-0c57-40b0-a785-a7a507e13dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os textos de exemplo da biblioteca.\n",
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73fba2c5-1a4c-4666-a860-0f684e6fb300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent1: Call me Ishmael .\n",
      "sent2: The family of Dashwood had long been settled in Sussex .\n",
      "sent3: In the beginning God created the heaven and the earth .\n",
      "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
      "sent5: I have a problem with people PMing me to lol JOIN\n",
      "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
      "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
      "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'sents' é um método que nos revela uma frase pertencente a cada texto da coleção.\n",
    "print(sents())\n",
    "\n",
    "# Podemos acessr uma das sentenças disponíveis com as variáveis 'sent{numero_do_texto}'.\n",
    "sent7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba7a7a-653a-41c1-8edf-dea2e82dac7e",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>FreqDist</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d5238ef-053b-459a-93e1-b8756f84bc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para essa parte introdutória à biblioteca, nos atentaremos ao text7, cuja fonte é o The Wall Street Journal.\n",
    "\n",
    "# A classe 'FreqDist' retorna uma espécie de dicionário com a contagem de ocorrência de cada token no texto.\n",
    "dist = FreqDist(text7)\n",
    "\n",
    "# Quantas vezes a palavra 'dollar' aparece no excerto?\n",
    "dist['dollar']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b629b-35e9-4577-862e-19bfad04bfae",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>Normalization and Stemming</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O processo de normalização dos termos de um texto é algo extremamente recomendável em tarefas de NLP. Por exemplo, a palavra 'List' e 'list', apesar de significarem a mesma coisa, não são consideradas iguais pelo computador por estarem escritas de maneira distinta.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f0114d3-cd74-46c5-ad6b-8d039031a219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listed', 'listing', 'list']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se quiséssemos analisar as palavas da lista 'roots', por exemplo, seria importante colocarmos todas as palavras em letra minúscula.\n",
    "roots = ['list', 'listed', 'listing', 'List']\n",
    "roots = [word.lower() for word in roots]\n",
    "roots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794734e3-4123-48d3-9073-75b2e6c87fea",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            'Stem', do inglês, quer dizer 'tronco'. Gramaticamente, procurar o 'stem' de uma palavra é equivalente a descobrir o que chamamos de <strong>raiz</strong>.\n",
    "        </li>\n",
    "        <li> \n",
    "            Em análise de textos, às vezes é interessante que convertamos palavras distintas com mesma raiz em uma única só.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00032aef-4a53-429a-93f1-0799e6e9f5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['list', 'list', 'list', 'list']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'univers'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual é a raiz dos termos de 'roots'?\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "# No caso do algoritmo Porter Stemmer, todas as variações e 'list' são transformadas. É uma abordagem radical que nem sempre desejamos.\n",
    "# Além disso, esse pode nos retornar palavras inexistentes na língua inglesa, dependendo do termo que sofre a normalização. Veja o que\n",
    "# ocorre com 'universal'.\n",
    "print([porter.stem(word) for word in roots])\n",
    "porter.stem('universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f356b7c-a2dc-4c3e-9a94-8909bc8a93d6",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>Lemmatization</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            É considerando esse retorno possivelmente indesejado de Porter que existe o processo de Lemmatização. O seu algoritmo no nltk retorna uma palavra existente quando fazemos um stemming.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9310d61d-2f28-438b-9ba9-a90b2d72ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "WNLemma = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041d195-f0dd-400d-ac61-91c5a27539c7",
   "metadata": {},
   "source": [
    "<p style='color:red'> Parei em 9:20 da aula \"Basic NLP tasks with NLTK\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
