{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357afeaf-8399-49e5-918d-dd69e9237786",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Classification of Text</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b917510-d898-4592-8861-aad58c04ec27",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Text Classification</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Classificar um texto pode ser algo de extremo valor. No caso de um website de emails, por exemplo, o Machine Learning é explorado a fim de se identificar emails spam.\n",
    "        </li>\n",
    "        <li> \n",
    "            Da mesma forma que praticamos no terceiro curso da especialização, elaborar um classificador de texto envolve, sempre, uma fase de treino; às vezes, de validação; e, por fim, uma de testes.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <h1> Workflow de ML para NLP</h1>\n",
    "    <img src='ml_workflow.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Assim como tarefas em datasets planilhados, é totalmente concebível construirmos modelos para multi-output classification.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da0386-5b31-4a3e-b9b3-94a620afa91c",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Identifying Features from Text</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f9828b-c19f-403c-bfd6-23c378e9f331",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O professor discorre sobre algumas práticas que devem ser levadas em conta quando fazemos trabalhos de NLP.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<h3 style='font-size:30px;font-style:italic'> Boas condutas em NLP</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Desconsiderar palavras irrelevantes, como preoposições e conjunções.\n",
    "        </li>\n",
    "        <li> \n",
    "            Lematização e Stemming.\n",
    "        </li>\n",
    "        <li> \n",
    "            Escolher quando a normalização deve ser adequada. Por exemplo, \"US\", de Estados Unidos acaba por ser confundido com o pronome \"us\", quando colocado em minúsculas.\n",
    "        </li>\n",
    "        <li> \n",
    "            Identificação de classes gramaticais.\n",
    "        </li>\n",
    "        <li> \n",
    "            Agrupar termos de mesma categorias, (Mr, Mrs, Phd...), datas.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aeffbe-a088-49e4-995a-e4c5dbf41898",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Naive Bayes Classifiers</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e043d5-ab5c-4bea-b5d6-9abd2da5683d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Funcionamento.</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Em classificações textuais, temos que oferecer todos os rótulos possíveis que um documento pode receber. De imediato, a probabilidade de cada categoria por si só é computada. Ou seja, as categorias tidas como mais recorrentes receberão uma probabildiade maior a despeito das outras.\n",
    "        </li>\n",
    "        <li> \n",
    "            Com essa etapa feita, o algoritmo estará apto para mensurar as probabilidades de rótulos dado um input (no caso, um texto). \n",
    "        </li>\n",
    "        <li> \n",
    "            Poderíamos montar uma ferramenta de busca que pudesse prever o assunto da query entre \"entretenimento\", \"ciência da computação\" e \"zoologia\", com ela entendendo que a primeira categoria é a mais recorrente. Como ela rotularia uma query \"Python\"?\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71057e-889c-4263-b674-a42e83585343",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src='bayes_prob1.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Neste caso, o algoritmo de bayes multiplicaria as probabilidades-padrão de uma dada categoria à chance de uma consulta pertencente a esse mesmo rótulo ter \"Python\" em seu texto. O produto dessa operação, enfim, é dividido pela chance da palavra \"Python\" se vista, de maneira geral, em qualquer query. Todos esses dados seriam estimados na fase de treino do algoritmo.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9640b9-1175-4ef6-aa54-d15c2fd9f049",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Suavizando o modelo</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            É importante nos atentarmos a casos excepcionais no processo de aprendizado. E se a palavra \"Python\" nunca tivesse aparecido nas consultas de \"Ciência da Computação\" no dataset de treino? Observe que pela fórmula, a probabilidade de esse termo ser designado à categoria mencionada se resultaria em 0. Mas isso seria adequado? \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='bayes_smoothing.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Considerando isso, técnicas como o Laplace ou Aditive smoothing foram criadas\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec3c91-9cc2-42e9-bf86-bc6cd1f6add9",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> Overview de Naïve Bayes</h1>\n",
    "    <img src='bayes_overview.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cd3b1-c753-4fdf-99c1-b8df2c945665",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Naïve Bayes Variations</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59534c-eb35-4328-b775-b9c7f5ec83df",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Multinomial Naïve Bayes</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O Multinomial Naïve Bayes é um modelo de classificação textual que leva em conta o número de ocorrências de uma palavra.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<h3 style='font-size:30px;font-style:italic'> Bernoulli Naïve Bayes</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Já o Bernoulli Naïve Bayes considera apenas a presença ou ausência dos termos no documento.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15158309-d420-47e6-87b9-d4ea8d5de444",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Support Vector Machines</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd56636-c9ba-4303-9569-8faa807621fc",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> Representação gráfica de modelos de NLP</h1>\n",
    "    <img src='svm1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27435e77-73cd-4ff5-9997-d68f85a4bffe",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'>Learning Text Classifiers in Python</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a7cf9-954a-4427-81ab-8782f64c1381",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> Algumas das classes do NLTK para ML</h1>\n",
    "    <img src='nltk_models1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831c394-f059-42b8-b901-88d2f59b7810",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> Exemplo de um Naïve Bayes com o NLTK</h1>\n",
    "    <img src='nltk_models2.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3f254-056a-413c-8556-ef0bec989f1f",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> Uso de modelos do sklearn com SklearnClassifier</h1>\n",
    "    <img src='nltk_models3.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Passe o modelo desejado como argumento do objeto SklearnClassifier.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a6250-aabe-4c51-97b6-4f54729f0a40",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <hr>\n",
    "    <h2 style='font-size:30px'> Demonstration: Case Study - Sentiment Analysis</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a030be-cbe4-4ae9-a6ec-48c3862dc6f1",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Esta aula tem como foco a aplicação dos conceitos aprendidos em uma análise de sentimentos sobre revisões no site da Amazon.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff506e72-cd13-43d3-b9e0-e884367ee4f1",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Importando os dados e limpando-os</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Vamos começar removendo as revisões de 3 estrelas, considerando-as neutras. Além disso, é necessário criar uma coluna target-value.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33bea684-d958-403e-83fd-299554295191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Amazon_Unlocked_Mobile.csv').query('Rating!=3')\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e51d37e7-5fe3-4d83-b080-17958323bd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \\\n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0   \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0   \n",
       "2       5                                       Very pleased           0.0   \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0   \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0   \n",
       "\n",
       "   Positively Rated  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a coluna alvo.\n",
    "df['Positively Rated'] = np.where(df.Rating>3, 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b0a08-8681-4958-9447-647dc3a0185c",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> train_test_split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8593049-ff32-4644-8e4a-251e874c69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vamos utilizar apenas a coluna \"Reviews\" como variável independente.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], df['Positively Rated'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e97eb1-1bd3-4bf0-b004-b760bcafa901",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Count Vectorizer</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           Aplicar um CountVectorizer sobre os dados textuais é uma das estratégias mais comuns do ML em NLP. Ele cria uma matriz com a contagem de ocorrência de cada token. Vale mencionar que as palavras são automaticamente postas em minúsculas.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d8fe8b3-e2e4-4862-bf7f-616b3e41a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e06f881e-38ad-4e18-9bef-50cc5630206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veiga/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '4less',\n",
       " 'adr6275',\n",
       " 'assignment',\n",
       " 'blazingly',\n",
       " 'cassettes',\n",
       " 'condishion',\n",
       " 'debi',\n",
       " 'dollarsshipping',\n",
       " 'esteem',\n",
       " 'flashy',\n",
       " 'gorila',\n",
       " 'human',\n",
       " 'irullu',\n",
       " 'like',\n",
       " 'microsaudered',\n",
       " 'nightmarish',\n",
       " 'p770',\n",
       " 'poori',\n",
       " 'quirky',\n",
       " 'responseive',\n",
       " 'send',\n",
       " 'sos',\n",
       " 'synch',\n",
       " 'trace',\n",
       " 'utiles',\n",
       " 'withstanding']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alguns dos tokens de nosso X_train. \n",
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c2826ba-fa10-4263-a56b-c52e2d4c9989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<231207x53216 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6117776 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando 'X_train' em uma matriz esparsa do scipy.\n",
    "# Cada linha representa o texto de uma review, as colunas indicam cada token do vocabulário.\n",
    "# O valor de cada célula é o número de ocorrências do token em uma determinada review.\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d7a05-e7f0-4062-820d-532e10710642",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Logistic Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0364921f-e8c3-46b8-9189-1568381485a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veiga/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e6efeb4-d267-41c9-bd88-13e0d440d961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265439531807432"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medidno o roc_auc do modelo.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Transformando 'X_test'. Note que os tokens que não estavam presentes em 'X_train' serão ignorados.\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8b717c9-bedb-4d7a-a4df-78b4c0a28b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typical Words from bad reviews: ['worst' 'false' 'worthless' 'junk' 'mony' 'garbage' 'useless' 'messing'\n",
      " 'unusable' 'horrible']\n",
      "Typical Words from good reviews: ['lovely' 'amazing' 'perfecto' 'efficient' 'loves' 'loving' 'excellent'\n",
      " 'exelente' 'excelente' 'excelent']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veiga/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "bottom_top = model.coef_[0].argsort()\n",
    "\n",
    "print(f'Typical Words from bad reviews: {feature_names[bottom_top[:10]]}')\n",
    "print(f'Typical Words from good reviews: {feature_names[bottom_top[-10:]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a52692-eeff-41aa-bda5-4155e7ebbfc7",
   "metadata": {},
   "source": [
    "<p style='color:red'> Demonstration: Case Study - Sentiment Analysis (4:40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
