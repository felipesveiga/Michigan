{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f838984-212a-4223-bc16-388ed2802160",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:40px'> Supervised Machine Learning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d94d6-43f7-4387-92d7-6acc9ad29cbe",
   "metadata": {},
   "source": [
    "<h2 style = 'font-size:30px'> Introduction to Supervised Machine Learning</h2>\n",
    "<h3 style = 'font-size:30px'> <em>Conceitos Adicionais de Supervised Learning</em></h3>\n",
    "<div>\n",
    "    <ul style = 'font-size:20px'>\n",
    "        <li>\n",
    "            Existem dois tipos de modelos de classificação. O primeiro seria o classificador binário, que retorna apenas dois valores (\"sim\" ou \"não\", por exemplo). O segundo é conhecido como um classificador múltiplo, cuja quantidade de valores de previsão <strong>y</strong> é mais de dois.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff36940-3640-4f90-914b-6246e61bb040",
   "metadata": {},
   "source": [
    "<h2 style = 'font-size:30px'> <em>Os próximos modelos de Supervised Learning </em></h2>\n",
    "<div>\n",
    "    <ul style = 'font-size:20px'>\n",
    "        <li>\n",
    "         K-Nearest Neighbors: Muito preciso, mas altamente sensível a pequenas mudanças no dataset de treino.\n",
    "        </li>\n",
    "        <li>\n",
    "            Least-squares linear model: Possui menor precisão, mas é mais estável a mudanças no dataset de treino.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2861c-6e13-492d-a1b6-9ad0e8d3cfc6",
   "metadata": {},
   "source": [
    "<h3 style = 'font-size:30px'> <em> Definindo os melhores parâmetros para os modelos</em> </h3>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            A performance de um certo modelo dependerá da complexidade a qual estamos conferindo a ele ( por exemplo, o valor de n_neighbors em KNN) e de se a sua qualidade é medida com base no dataset de treino ou teste.\n",
    "        </li>        \n",
    "    </ul>    \n",
    "</div>\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "    <img src = 'chart1.png'>\n",
    "    </center>\n",
    "    <hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1063718-5fca-420f-a008-b5342f8bce03",
   "metadata": {},
   "source": [
    "<h2 style = 'font-size:30px'> Overfitting and Underfitting</h2>    \n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>\n",
    "        <li> Em Machine Learning, o overfitting de um modelo seria quando esse se torna \"viciado\" pelos dados de treino. Dessa forma, pode se tornar despreparado em lidar com valores excepcionais, que se desviam excessivamente daqueles do dataset de treino.\n",
    "        </li>        \n",
    "        <li>\n",
    "            O underfitting, por sua vez, ocorre quando o modelo simples demais em generalizar tanto os valores que o alimentaram, quanto aqueles que deverá prever.\n",
    "        </li>\n",
    "    </ul>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0cd9b6-fe84-41ff-96d5-7da2af3f3f12",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 style = 'font-size:40px'> Um exemplo de underfitting</h1>\n",
    "    <img src = 'underfitting1.png'>\n",
    "    \n",
    "    <h1 style = 'font-size:40px'> Um fit Ideal</h1>\n",
    "    <img src = 'fit1.png'>\n",
    "    \n",
    "    <h1 style = 'font-size:40px'> Overfitting</h1>\n",
    "    <img src = 'overfitting1.png'>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9d096-02ef-4c60-891d-2ce14fa512bc",
   "metadata": {},
   "source": [
    "<div>\n",
    "<ul style = 'font-size:20px'>    \n",
    "    <li>\n",
    "        Veja como o modelo <em>underfitted</em> mal consegue prever corretamente os resultados dos dados de treino. Por outro lado, o modelo <em>overfitted</em> está viciado no dataset de treino, o que pode tornar as suas previsões dos dados de teste imprecisas. \n",
    "    </li>    \n",
    "    <li>\n",
    "        A ideia por trás da criação de um bom modelo de Machine Learning é a de que ele deve ser capaz de fazer uma boa generalização dos dados de teste, sem ter um foco excessivo nas potenciais exceções.\n",
    "    </li>   \n",
    "</ul>\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e62bc1-6b48-4f94-be47-38552ee30194",
   "metadata": {},
   "source": [
    "<h2 style = 'font-size:30px'> K-Nearest Neighbors: Classification and Regression</h2>\n",
    "<h3 style = 'font-size:30px'> <em>Regression</em> </h3>\n",
    "<div> \n",
    "    <ul style = 'font-size:20px'>   \n",
    "        <li>\n",
    "            O modelo de KNN para regressões tem um funcionamento um pouco distinto com relação ao de classificações.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div>\n",
    "<center>\n",
    "    <img src = 'knn_reg.png'>\n",
    "</center>\n",
    "</div>\n",
    "<div>      \n",
    "    <ul style = 'font-size:20px'>   \n",
    "        <li>\n",
    "            No caso da imagem acima, quando K = 3, a altura do ponto de abscissa -1.25 será a média das ordenadas dos seus três pontos mais próximos (representada pelos triângulos azuis).\n",
    "        </li>\n",
    "        <li>\n",
    "            O modelo de regressão no scikit-learn recebe o nome de KNeighborsRegressor (KNeighborsClassifier é voltado  apenas a problemas de classificação).\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<h4 style = 'font-size:25px'> <em> <u> R&#178;</u> </em> </h4>\n",
    "<div>\n",
    "    <ul style = 'font-size:20px'>   \n",
    "        <li>\n",
    "            A métrica R&#178; é responsável por avaliar a qualidade do modelo, sendo 0 o seu pior desempenho - quando seu output sempre será a média das ordenadas de todos os pontos do dataset de treino. Já 1 indica o maior grau de perfeição do algoritmo.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92aace-c053-44be-b891-6614d16fd461",
   "metadata": {},
   "source": [
    "<h2 style = 'font-size:30px'> Linear Regression: Least-Squares</h2>\n",
    "<div>\n",
    "    <ul style = 'font-size:20px'>   \n",
    "        <li> \n",
    "            A Regressão Linear consiste na elaboração de uma fórmula de soma ponderada capaz de prever um dado valor.\n",
    "        </li>\n",
    "        <li>\n",
    "            Por exemplo, poderíamos usar esse modelo de Machine Learning na previsão de valores numéricos, como o preço de um imóvel e a cotação de uma moeda.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div>\n",
    "    <center>\n",
    "        <img src = 'least_squares1.png'>\n",
    "    </center>\n",
    "    <div>  \n",
    "        <ul style = 'font-size:20px'>   \n",
    "            <li>\n",
    "                Na imagem, uma esquematização de uma fórmula de Regressão Linear é dada.\n",
    "            </li>\n",
    "            <li>\n",
    "                Nela, os elementos <em>w</em> são os coeficientes - ou os pesos - para cada variável <em>xi</em>. Além disso, toda fórmula desse modelo recebe um valor independente <em>b</em>.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2446368-2b75-4101-824c-de3aedbc06d3",
   "metadata": {},
   "source": [
    "<h3 style = 'font-size:30px'> <em> Descobrindo os coeficientes </em> </h3>\n",
    "\n",
    "<div>\n",
    "    <ul style = 'font-size:20px'>\n",
    "        <li>\n",
    "            Utilizaremos o método <em>least-squares</em> para encontrarmos os coeficientes ideais de nosso modelo de Regressão Linear.\n",
    "        </li>     \n",
    "    </ul>\n",
    "        <div>\n",
    "            <center>\n",
    "                <img src = 'least_squares2.png'>\n",
    "            </center>\n",
    "        </div>\n",
    "    <ul style='font-size:20px'>\n",
    "        <li>\n",
    "            Como é possível perceber na figura, a melhor linha a ser escolhida será aquela cuja soma das distâncias entre a reta e as ordenadas dos dados de treino - elevadas ao quadrado - for menor\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78a5f663-ad54-4cc7-813a-59c85111f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, colocaremos em prática um modelo de Least-Squares Regression.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c033931-c1e5-46dc-9ee3-76f0c268c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos um dataset do curso de Machine Learning da IBM.\n",
    "# Ele trata da emissão de CO2 por carros de diferentes tipos\n",
    "cars = pd.read_csv('FuelConsumption.csv')\n",
    "X = cars[['ENGINESIZE']]\n",
    "y = cars['CO2EMISSIONS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2da6af9-1578-4dce-ac35-0de60aa3e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão do modelo foi de : 72.03%\n"
     ]
    }
   ],
   "source": [
    "# Treinando o nosso modelo e obtendo a sua precisão com os dados de teste.\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "prec = linreg.score(X_test, y_test)\n",
    "print(f'A precisão do modelo foi de : {prec :.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88f0981c-f2e7-4dc9-b706-86389054d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'CO2EMISSION')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vamos plotar um gráfico com a solução encontrada pelo modelo.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X_train, (linreg.coef_ * X_train) +(linreg.intercept_), color = 'grey')\n",
    "plt.scatter(X_test, y_test,s = 10 ,color = 'b')\n",
    "plt.title('Linear Regression Model X Test sample')\n",
    "\n",
    "plt.xlabel('ENGINESIZE')\n",
    "plt.ylabel('CO2EMISSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8af848ac-fc68-4a25-8881-05a45a5e09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, vamos fazer o mesmo procedimento com o algoritmo KNN.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c2e9693-0d4f-46cc-a1f4-49c57decdcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('FuelConsumption.csv')\n",
    "X = cars[['ENGINESIZE']]\n",
    "y = cars['CO2EMISSIONS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab578825-a897-472c-baee-3e14cf1169ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão do modelo foi de: 78.87%\n"
     ]
    }
   ],
   "source": [
    "# Treinando e testando o nosso modelo de KNN. Observe que ele, com n_neighbors = 5, é mais preciso do que \n",
    "# o modelo de regressão linear.\n",
    "knn = KNeighborsRegressor(n_neighbors = 5).fit(X_train, y_train)\n",
    "prec = knn.score(X_train, y_train)\n",
    "print(f'A precisão do modelo foi de: {prec :.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6919c-c29d-4867-abcb-28b5e7cdf736",
   "metadata": {},
   "source": [
    "<div>\n",
    "<hr>\n",
    "<h2 style = 'font-size:30px'> Linear Regression: Ridge, Lasso, and Polynomial Regression</h2>\n",
    "<div>\n",
    "    <h3 style = 'font-size:30px'> <em> Ridge Regression </em> </h3>\n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            A Ridge Regression pode ser entendida como uma Regressão em least-squares com a adição de um termo de penalidade para os coeficientes <em>w</em> de grande valor (os seus valores ao quadrado somados).\n",
    "        </li>     \n",
    "        <li>\n",
    "            A intenção desse termo adicional é diminuir a complexidade do modelo, tornando-o menos viciado ao dataset de treino.\n",
    "        </li>      \n",
    "    </ul>   \n",
    "    <div>        \n",
    "        <center>\n",
    "            <h1 style = 'font-size:30px'> Fórmula da Regressão Ridge</h1>\n",
    "            <img src = 'ridge_formula.png'>\n",
    "        </center>        \n",
    "    </div>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7c8ff5b1-222b-404c-b398-e21af4aeb3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>545.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>124.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>353.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>691.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>918.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1\n",
       "0      41.02\n",
       "1     127.56\n",
       "2     218.59\n",
       "3     306.64\n",
       "4     442.95\n",
       "...      ...\n",
       "1989  545.75\n",
       "1990  124.10\n",
       "1991  353.83\n",
       "1992  691.17\n",
       "1993  918.89\n",
       "\n",
       "[1994 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aqui, iremos aplicar essa regressão em um dataset sobre criminalidade.\n",
    "# Observe que essa regressão admite várias colunas como variáveis independentes.\n",
    "# A partir de uma série\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "# Os dados X e y já vem prontos (fiz isso manualmente do Coursera).\n",
    "X = pd.read_csv('X.csv', sep = ',').drop(columns = ['index'])\n",
    "y = pd.read_csv('y.csv', sep = ',', header = None).drop(columns = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a16825d0-2959-4f33-9e93-028493cefdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4940490145966756"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando os dados de treino e testagem.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "linridge = Ridge(alpha = 20.0).fit(X_train, y_train)\n",
    "linridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9386759-f17d-4268-9772-2c4b983c585a",
   "metadata": {},
   "source": [
    "<h2 style = 'font-size:30px;color:orange'> Digressão: normalizando dados</h2>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            A fim de aperfeiçoar os nossos modelos, é importante colocarmos todos os nossos dados em uma mesma escala - processo conhecido como a <strong>normalização</strong>. Dessa forma, todas as features terão o mesmo peso em nossa análise.\n",
    "        </li>       \n",
    "        <li>\n",
    "            O primeiro algoritmo de normalização que veremos é o Min-Max Scaling, ele criará uma escala em que o menor valor dos dados se tornará 0 e o maior 1.\n",
    "        </li>      \n",
    "    </ul>  \n",
    "</div>\n",
    "<div>\n",
    "    <center>\n",
    "        <h1 style = 'font-size:30px'>Fórmula do Min-Max Scaling </h1>\n",
    "        <img src = 'min_max.png'>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "61c74555-6164-49d8-b09a-97ada019f873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5986066019999294"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos aplicar essa normalização com os dados vistos.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# O método fit_transform identificará os máximos e mínimos (fit) de cada coluna e aplicará \n",
    "# a fórmula do Min-max Scaling (transform).\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Como não podemos 'fittar' o nosso scaler de acordo com o 'X_test', deveremos apenas 'tranformar' os seus dados.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linridge = Ridge(alpha = 20).fit(X_train_scaled , y_train)\n",
    "# A normalização dos dados foi capaz de aumentar a precisão do modelo em 10%!\n",
    "linridge.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760a6f2-ab94-4cea-96da-dbd951d6a997",
   "metadata": {},
   "source": [
    "<h3 style = 'font-size:30px'> <em> Lasso Regression</em> </h3>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>       \n",
    "        <li>\n",
    "            Em Regressão Lasso, a fórmula da Least-Squares recebe, também, um termo de penalidade. Diferentemente da Ridge Regression, esse consiste na soma dos módulos dos coeficientes <em>w</em>.\n",
    "        </li>        \n",
    "        <li>\n",
    "            O efeito final desse termo é o de neutralizar os coeficientes de menor valor na fórmula, igualando-os a zero. Portanto, use a Lasso caso pense que apenas alguns parâmetros têm, de fato, uma grande ou média influência sobre o resultado esperado.\n",
    "        </li>        \n",
    "    </ul>   \n",
    "    <div>\n",
    "        <center>\n",
    "            <h1 style = 'font-size:30px'> Fórmula da Regressão Lasso</h1>\n",
    "            <img src = 'lasso_formula.png'>\n",
    "        </center>       \n",
    "    </div>   \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b527df4-252f-4add-b76e-439407901924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indo para a parte prática\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X = pd.read_csv('X.csv').drop(columns = 'index')\n",
    "y = pd.read_csv('y.csv', header = None).drop(columns = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Normalizando os dados, como anteriormente.\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d712452c-1d3d-4737-b299-ff578be52d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6237725857015401"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceba, para esse dataset, a Lasso ofereceu uma maior precisão.\n",
    "lasso = Lasso(alpha = 2).fit(X_train_scaled, y_train)\n",
    "lasso.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3836c72-8408-44c9-b578-3d7743c12aff",
   "metadata": {},
   "source": [
    "<h3 style = 'font-size:30px'> <em> Polynomial Regression</em> </h3>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            A Regressão Polinomal ocorre quando buscamos criar novas variáveis na nossa fórmula de regressão com a combinação multiplicativa das variáveis independentes.\n",
    "        </li>       \n",
    "    </ul>        \n",
    "     <div>            \n",
    "            <center>\n",
    "                <h1 style = 'font-size:30px'> Um exemplo de Regressão Polinomial e sua Fórmula</h1>\n",
    "                <img src = 'polynomial_formula.png'>\n",
    "            </center>           \n",
    "        </div>   \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            No exemplo, temos duas variáveis independentes <em>xo</em> e <em>x1</em>. A fim de ampliar a complexidade de uma possível Regressão, decidimos por criar novas variáveis em sua fórmula, como o quadrado de <em> xo</em> e <em>xo * x1 </em>.\n",
    "        </li>       \n",
    "    </ul>    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f23b8-b3f3-4511-a09d-46ca47773804",
   "metadata": {},
   "source": [
    "<h4 style = 'font-size:25px'> <em> <u> Cuidados com a Polynomial Regression</u> </em> </h4>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            Como desejamos aumentar a complexidade de nosso modelo, é necessário evitar radicalismos para impedir o seu vício.\n",
    "        </li>        \n",
    "        <li>\n",
    "            Dessa forma, é recomendado performar a Polynomial Regression em uma Ridge Regression.\n",
    "        </li>        \n",
    "    </ul>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01572619-d8a7-46e7-852d-412aeb40a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial RegressionAccuracy: 0.7924758016881502\n",
      "Ordinary Ridge Regression Accuracy: 0.6984927742769003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_friedman1\n",
    "\n",
    "# Criando as variáveis dependentes e independentes\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)                                      \n",
    "\n",
    "# Aplicando o método PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly.fit_transform(X_F1)\n",
    "\n",
    "# Dividindo o dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y_F1, random_state = 0)\n",
    "\n",
    "# Fazendo a Ridge Regression.\n",
    "ridge = Ridge(alpha = 2).fit(X_train, y_train)\n",
    "print(f'Polynomial RegressionAccuracy: {ridge.score(X_test, y_test)}')\n",
    "\n",
    "# Agora, vamos fazer a Ridge Regression sem o pré-processamento.\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_F1, y_F1, random_state = 0)\n",
    "ridge_ = Ridge(alpha = 2).fit(X_train_, y_train_)\n",
    "print(f'Ordinary Ridge Regression Accuracy: {ridge_.score(X_test_, y_test_)}')\n",
    "\n",
    "# Veja, o pré-processamento fez com que a precisão subisse em 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eab32c-96f1-4459-9777-f9626f6bafaa",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "<h2 style = 'font-size:30px'> Logistic Regression</h2>\n",
    "\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            Apesar de conter a palavra <em>Regression</em> em seu nome, a Regressão Logística é utilizada mais em modelos de classificação.\n",
    "        </li>       \n",
    "        <li>\n",
    "            A sua intenção é de realizar uma classificação binária a partir dos dados de input\n",
    "        </li>\n",
    "    </ul>    \n",
    "</div>\n",
    "<div>    \n",
    "    <center>       \n",
    "        <img src = 'logistic_regression1.png'>       \n",
    "    </center>    \n",
    "</div>\n",
    "<div>   \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            A Regressão Logística transformará os dados de input em uma função em formato de S. O valor final dessa é a probabilidade de a instância sendo analisada pertencer à porção positiva do eixo x.\n",
    "        </li>       \n",
    "    </ul>   \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e41fe7-567c-4c01-b430-5119b4e1e64d",
   "metadata": {},
   "source": [
    "<div>    \n",
    "    <center>\n",
    "        <h1 style = 'font-size:30px'>Chance de aprovação por horas de estudo </h1>\n",
    "        <img src = 'logistic_regression2.png'>       \n",
    "    </center>\n",
    "</div>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            Aqui, montamos uma função de regressão logística com base no número de horas de estudos de alunos que passaram ou foram reprovados no teste. O resultado final é uma curva em S que demonstra a probabilidade de se passar no exame com base no tempo dedicado à matéria da prova.\n",
    "        </li>       \n",
    "    </ul>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc14301-0f1e-4db2-949c-740805c01e8a",
   "metadata": {},
   "source": [
    "<h3 style = 'font-size:30px;font-style:italic'> Regressão Logística Binária</h3>\n",
    "<div>    \n",
    "    <center>       \n",
    "        <img src = 'logistic_regression3.png'>       \n",
    "    </center>    \n",
    "    <div>      \n",
    "        <ul style = 'font-size:20px'>            \n",
    "            <li>\n",
    "            No gráfico, existem duas famílias de dados que possuem valores para as Features 1 e 2.\n",
    "            </li>\n",
    "            <li>\n",
    "                Nesse caso, a aplicação de uma Regressão Logística a esse dataset acarretaria em uma função tridimensional, com a criação de um eixo y vertical ao encontro dos eixos bidimensionais. Observe abaixo como a curva em S se aparentaria.\n",
    "            </li>            \n",
    "        </ul>       \n",
    "    </div>   \n",
    "    <center>    \n",
    "        <img src = 'logistic_regression4.png'>     \n",
    "    </center>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9fb475-97e9-456d-b637-e1f4170e8b4e",
   "metadata": {},
   "source": [
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            Por questões de simplicação, somos capazes também de extrair a projeção ortogonal dessa curva sobre o plano das Features - com a óbvia perda da figura em S.\n",
    "        </li>        \n",
    "    </ul>    \n",
    "    <div>        \n",
    "        <center>            \n",
    "            <img src = 'logistic_regression5.png'>             \n",
    "        </center>        \n",
    "    </div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d84d258-9dcc-4b8f-b492-ebd307068610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Vamos fazer um modelo de detecção de maçãs com base na altura e largura da fruta.\n",
    "# True serão as maçãs, False, as não-maçãs\n",
    "fruits = pd.read_csv('fruit_data_with_colors (1).txt', sep = '\\t', usecols = ['fruit_label', 'height', 'width'])\n",
    "fruits['fruit_label'].replace(1, True, inplace = True)\n",
    "fruits['fruit_label'].replace([2,3,4], False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220acad9-9fc2-4a15-9d95-72cfd7058ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = fruits[['width', 'height']]\n",
    "y = fruits['fruit_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0)\n",
    "\n",
    "# Aplicando a regressão. Quanto maior o valor de C, mais complexo o modelo será\n",
    "clf = LogisticRegression(C = 100).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e45ae6c-91b6-41ae-9136-b2ce879f79d5",
   "metadata": {},
   "source": [
    "<div>\n",
    "<hr>\n",
    "<h2 style = 'font-size:30px'>Linear Classifiers: Support Vector Machines</h2>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            Esse algoritmo de classificação busca criar uma linha no plano cartesiano que seja capaz de melhor segregar as instâncias dos diferentes grupos sendo analisados.\n",
    "        </li>      \n",
    "        <li>\n",
    "            A linha ideal - chamada de Support Vector Macine - será aquela que tem a maior distância com o primeiro ponto de instância de treino.\n",
    "        </li>        \n",
    "        <div>           \n",
    "            <center>\n",
    "                <img src = 'vector_machines1.png'>\n",
    "            </center>           \n",
    "        </div>\n",
    "    </ul>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            A partir dessa reta, o modelo classificará as instâncias de teste de acordo com as suas coordenadas no plano.\n",
    "        </li>       \n",
    "        <li>\n",
    "            Por exemplo, digamos que a equação da <em> Support Vector Machine </em> seja 5x + 2y - 1 = 0. A função de classificação final será f([x,y], w,b) = 5x + 2y - 1. \n",
    "        </li>        \n",
    "        <li>\n",
    "            Se tivermos uma instância do dataset de teste com as coordenadas (1,-1), as aplicaremos na fórmula da função, que ficará como 5(1) + 2(-1) -1 = 2. Como 2 está mais próximo de 1 do que -1, tal instância ficará rotulada como \"1\".\n",
    "        </li>       \n",
    "    </ul>    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b83d635-756c-4bd2-903a-f4ed208a48ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_C2, y_C2 = make_classification(n_samples = 100, n_features=2,\n",
    "                                n_redundant=0, n_informative=2,\n",
    "                                n_clusters_per_class=1, flip_y = 0.1,\n",
    "                                class_sep = 0.5, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2, random_state = 0)\n",
    "clf = SVC(kernel='linear', C=1.0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1fff15-5aab-471e-9158-081c79b0ed79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar ao SVC, mas com kernel = 'linear' e maior flexibilidade na escolha de penalidades e loss functions.\n",
    "clf = LinearSVC(C=1.0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfb8ae4-fb40-4eca-bab2-fef4c5e3d965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipeveiga/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8601398601398601"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando o algoritmo no dataset de cancer (projeto de KNN da primeira semana do curso).\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X_cancer, y_cancer = load_breast_cancer(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c9619-2edd-4d91-a568-34996704a53b",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:30px; text-align:center'> Quadro Prós-Contras sobre Linear Models</h1>\n",
    "<div>    \n",
    "    <center>\n",
    "        <img src = 'linear_models_pro_con1.png'>\n",
    "    </center>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae82ef-e062-4c43-b98b-9cc34047f783",
   "metadata": {},
   "source": [
    "<div>\n",
    "<hr>\n",
    "<h2 style = 'font-size:30px'>Multi-Class Classification </h2>\n",
    "<div>    \n",
    "    <ul style = 'font-size:20px'>        \n",
    "        <li>\n",
    "            Quando queremos que o scikit learn lide com a classicação múltipla, ele aplicará um modelo de classificação binária para cada categoria que queremos analisar.\n",
    "        </li>        \n",
    "        <li>\n",
    "            No contexto da dataset sobre frutas, a biblioteca primeiro fará, por exemplo, um Support Vector Machine para as Maçãs e não-Maçãs; depois disso, para as Laranjas e não-laranjas e assim por diante.\n",
    "        </li>        \n",
    "        <li>\n",
    "            Para uma instância de rótulo desconhecido, sua categoria será da Support Vector Machine com o maior valor de output (lembre-se, todo SVM produz uma fórmula de classificação binária). Portanto, se a SVM de Laranjas tiver retornado o maior número -digamos, 2.05-, a instância será rotulada como uma laranja.\n",
    "        </li>        \n",
    "    </ul>    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78fd07d4-03f1-46ae-b450-d40ce9c5a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipeveiga/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.30006303,  0.71557482],\n",
       "       [-1.62785586,  1.15837035],\n",
       "       [ 0.00721513,  0.43311565],\n",
       "       [ 1.2474674 , -1.64209043]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "fruits = pd.read_csv('fruit_data_with_colors (1).txt', sep = '\\t', usecols = ['fruit_label', 'height', 'width'])\n",
    "X = fruits[['height', 'width']]\n",
    "y = fruits['fruit_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "clf = LinearSVC(C=5, random_state=67).fit(X_train, y_train)\n",
    "\n",
    "# Veja, o sklearn produziu 4 funções de SVM.\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c420f55e-65a9-4d26-962d-b461f155f352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nesse contexto, o SVM cuja função retornar o maior número rotulará a instância dada.\n",
    "clf.predict([[5,5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804f0c9-aa82-4853-bc07-9f567ec99f09",
   "metadata": {},
   "source": [
    "<div>\n",
    "<hr>\n",
    "<h2 style='font-size:30px'> Kernelized Support Vector Machines</h2>\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            Os <em> Kernelized SVM</em> são recomendados em situações em que devemos classificar dados que não são facilmente distingíveis.\n",
    "        </li>      \n",
    "    </ul>       \n",
    "        <div>            \n",
    "            <center>\n",
    "                <img src='Kernelized_SVM.png'>\n",
    "            </center>            \n",
    "        </div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            No caso da imagem da esquerda, é possível perceber que as classes preta e amarela são facilmente diferenciáveis. No entanto, a situação da imagem à direita já é mais complicada. É nesse contexto que o Kernelized SVM surge como uma boa opção.\n",
    "        </li>       \n",
    "    </ul>    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab027a8-e6b7-49e6-ab66-3b8a2f639ada",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> O modus operandi do KSVM</h3>\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            A fim de diminuir a complexidade da segregação das instâncias, é possível utilizar os valores de suas coordenadas, aplicando-as à fórmula de uma função cujo output as separaria melhor pelo plano cartesiano.\n",
    "        </li>        \n",
    "    </ul>   \n",
    "    <div>        \n",
    "        <center>\n",
    "            <img src='kernelized_SVM2.png'>\n",
    "        </center>        \n",
    "    </div>    \n",
    "    <ul style='font-size:20px'>       \n",
    "        <li>\n",
    "            Por exemplo, aplicar um SVM linear decente à imagem da esquerda seria impossível. No entanto, poderíamos criar uma terceira dimensão ao plano, conferindo à coordenada Z das instâncias a fórmula 1-(xo&#178;+x1&#178;).\n",
    "        </li>        \n",
    "        <li>\n",
    "            Dessa maneira, as instâncias passam a se tornar facilmente segregáveis, bastando criar um plano com certa altura no eixo y que separe corretamente os pontos pretos dos brancos.\n",
    "        </li>        \n",
    "    </ul>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866958e-7712-42a2-a42c-c2408f04488e",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Os Kernels do KSVM </h3>\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            Os Kernels podem ser entendidos como medidas de similaridade entre os dados. Cada um deles elabora uma transformação diferente aos nossos dados para que eles se tornem melhor segregáveis.\n",
    "        </li>        \n",
    "    </ul>    \n",
    "</div>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91d5ee2d-369f-412c-8415-cd2bc944fa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kernel RBF.\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_D2, y_D2 = make_blobs(n_samples = 100, n_features = 2, centers = 8,\n",
    "                       cluster_std = 1.3, random_state = 4)\n",
    "y_D2 = y_D2 % 2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state=0)\n",
    "\n",
    "# gamma, assim como C controla o nível de complexidade do modelo. Acho que seria sensato evitar valores \n",
    "# desse parâmetroacima de 10.\n",
    "\n",
    "# gamma possui uma influência maior na complexidade do modelo do que C.\n",
    "clf = SVC(kernel='rbf', gamma=5, C=100).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2f24481-76ce-4018-8e10-0343832be274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos testar diferentes valores de gamma e C a fim de descobrir aqueles que nos darão o melhor modelo de SVC,\n",
    "df = pd.DataFrame({'gamma':[], 'C':[], 'score':[]})\n",
    "for gamma in range(1,11):\n",
    "    for C in range(1,101):\n",
    "        clf = SVC(kernel='rbf', gamma=gamma, C=C).fit(X_train, y_train).score(X_test, y_test)\n",
    "        df.loc[gamma * C,:] = [gamma, C, clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11d2f792-ccd9-410b-b089-669ee4ee011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gamma     C  score\n",
       "17    1.0  17.0   0.88"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O Python afirma que a melhor performance do modelo ocorre quando gamma = 1 e C = 17\n",
    "df[df['score'] == df['score'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19275ae3-da29-4843-a43a-addb3f9fa946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polynoial Kernel.\n",
    "# Esse é um outro kernel bastante útil na aplicação de SVM. Possui o modelo 'degree', que controla a complexidade\n",
    "# do modelo.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state=0)\n",
    "clf = SVC(kernel='poly', degree=3).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab8dde-c259-49b2-8d1c-54f4c86ec5d4",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <center>\n",
    "        <h1 style='font-size:30px'> Prós e Contras do SVM</h1>\n",
    "        <img src='vector_machines2.png'>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d0e3c-98f0-45df-bc91-3cd58eafe1a6",
   "metadata": {},
   "source": [
    "<div>\n",
    "<hr>\n",
    "<h2 style='font-size:30px'> Cross-Validation</h2>\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            Até este ponto do curso, buscamos construir os nossos conjuntos de dados para ML por meio de um único <em>train_test_split</em>.\n",
    "        </li>        \n",
    "        <li>\n",
    "            No entanto, é provável que poderíamos obter, por coincidência, um dataset que produza uma melhor performance de nosso modelo devido ao valor de parâmetros como o <em>random_state</em>, por exemplo.\n",
    "        </li>        \n",
    "        <li>\n",
    "            Tendo isso em vista, o <em>Cross-Validation </em> tenta fazer diversos <em>train_test_split's</em> diferentes em busca de um conjunto de dados \"ideal\" para uma maior precisão do modelo\n",
    "        </li>        \n",
    "    </ul>    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb5fcc-7b42-46bd-aed0-75a40173a2a1",
   "metadata": {},
   "source": [
    "<div>    \n",
    "    <center>\n",
    "        <h1 style='font-size:30px'> O funcionamento do Cross-Validation</h1>\n",
    "        <img src='cross1.png'>\n",
    "    </center>    \n",
    "    <div>        \n",
    "        <ul style='font-size:20px'>            \n",
    "            <li>\n",
    "                O algoritmo, primeiro, quebra o dataset em fragmentos, ou folds (quando quebrado em 5, falamos que houve um 5 fold cross-validation). Logo em seguida, o Python pegará um dos pedaços gerados e o colocará como dados de teste; o restante ficará para treino. Esse processo ocorrerá para cada uma das partições, a fim de sabermos qual quebra gerou o modelo com maior precisão.\n",
    "            </li>            \n",
    "            <li>\n",
    "                Esse método é muito bom para avaliarmos a sensibilidade do modelo sendo utilizado com o dataset que o alimenta.\n",
    "            </li>            \n",
    "        </ul>        \n",
    "        <p style='font-size:16px'> \n",
    "            \n",
    "            <u>Obs</u>: Cada fold produzido manterá, aproximadamente, a mesma proporção de categorias distintas que a do dataset de origem.           \n",
    "        </p>        \n",
    "    </div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88402050-f7f4-4584-9b64-b7257c9091b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88596491 0.93859649 0.93859649 0.94736842 0.92920354]\n",
      "O score médio foi de: 0.9279459711224964\n"
     ]
    }
   ],
   "source": [
    "# A aplicação do Cross-Validation torna o nosso código mais enxuto do que quando usamos train_test_split.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Buscando o dataset e importando um modelo de KNN.\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# O cross_val_score dividirá o dataset e aplicará o modelo automaticamente.\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(cv_scores)\n",
    "\n",
    "# É comum também calcularmos a média dos scores obtidos.\n",
    "print(f'O score médio foi de: {cv_scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de066004-c0e5-4530-bf11-2c4f38cfffdd",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Validation Curves</h3>\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            As curvas de validações são um recurso que é capaz de revelar a influência de um determinado parâmetro na performance do modelo sendo utilizado.\n",
    "        </li>        \n",
    "        <li>\n",
    "            Seu output serão as precisões do modelo para cada valor do parâmetro definidos.\n",
    "        </li>\n",
    "        \n",
    "    </ul>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a36efa6-b232-4678-b3a1-f0f79a05f0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9762533 , 0.97361478, 0.98421053],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]]),\n",
       " array([[0.91578947, 0.93684211, 0.91005291],\n",
       "        [0.62631579, 0.62631579, 0.62962963],\n",
       "        [0.62631579, 0.62631579, 0.62962963],\n",
       "        [0.62631579, 0.62631579, 0.62962963]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O método 'validation_curve' dividirá fará os datasets de treino e test, implicitamente, com a aplicação de\n",
    "# um Cross-Validation com o parâmetro 'cv' a ser definido por nós.\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_range = np.logspace(-3,3, 4)\n",
    "train_scores, test_scores = validation_curve(SVC(), X, y, param_name='gamma', \n",
    "                                             param_range=param_range, cv = 3)\n",
    "\n",
    "# As possuem as precisões de cada Cross-Validation feito com o valor especificado do parâmetro, neste caso, 'gamma'.\n",
    "# Como quisemos três Cross-Validations, o array terá três colunas. E como definimos quatro valores de 'gamma', ele\n",
    "# terá quatro linhas.\n",
    "train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a51a8eb-1977-458f-b2dc-a0c1d6dbf51d",
   "metadata": {},
   "source": [
    "<div>\n",
    "<hr>\n",
    "<h2 style='font-size:30px'> Decision-Trees</h2>\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            As árvores de decisão são um modelo de Machine Learning Supervisionado.\n",
    "        </li>        \n",
    "        <li>\n",
    "            Sua estrutura é composta por perguntas de gênero binário (Sim ou não), identificados como nós. O caminho criado por um conjunto de sim's e não's fará o modelo prever a classificação de uma determinada instância.\n",
    "        </li>        \n",
    "    </ul>   \n",
    "    <div>       \n",
    "        <center>\n",
    "            \n",
    "            <h1 style='font-size:30px'>Árvore de Decisão Sobre Animais</h1>\n",
    "            <img src='trees1.png'>            \n",
    "        </center>       \n",
    "    </div>    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00665b-3a54-40b2-8069-b68c22c3166c",
   "metadata": {},
   "source": [
    "<div>    \n",
    "    <center>\n",
    "        <h1 style='font-size:30px'> Árvores de Decisão com Flores Íris</h1>\n",
    "        <img src='trees2.png'>\n",
    "    </center>    \n",
    "</div>\n",
    "<div>    \n",
    "    <ul style='font-size:20px'>        \n",
    "        <li>\n",
    "            Para cada conglomerado de instâncias, o Python criará a bipartição que melhor segregará as categorias analisadas - ou seja, que produzirá pelo menos um grupo com certa homogeneidade de rótulos.\n",
    "        </li>        \n",
    "        <li>\n",
    "            Cada caixa mostrada terá o critério de separação usado; o número total de instâncias no agrupamento; o número de instâncias para cada categoria presente; e o nome da categoria predominante.\n",
    "        </li>       \n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba5ec0f-703d-46b1-94d8-e31174ad28c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score com o dataset de treino: 1.00\n",
      "Score com o dataset de teste: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Realizando uma breve Decision Tree no dataset sobre iris.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = load_iris(return_X_y = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(f'Score com o dataset de treino: {clf.score(X_train, y_train):.2f}')\n",
    "print(f'Score com o dataset de teste: {clf.score(X_test, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419dee74-efa6-450c-9e5a-cc5b00d79be2",
   "metadata": {},
   "source": [
    "<ul style='font-size:20px'>    \n",
    "    <li>\n",
    "        Note que o modelo prevê perfeitamente os dados de treino, o que provavelmente significa que há overfitting. Isso ocorre pois a árvore gerada é possivelmente complexa demais e busca chegar sempre a leafs puros (com apenas uma categoria).\n",
    "    </li>    \n",
    "    <li>\n",
    "        A fim de aumentar a capacidade GENERALIZANTE do modelo, podemos aproveitar o argumento <em>max_depth</em>, que especifica a profundidade máxima da árvore; <em>max_leaf_nodes</em>, que regulamenta o número máximo de folhas da árvore; e <em>min_samples_leaf</em>, que define o número de instâncias no nó para se considerar a separação.\n",
    "    </li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceeb7a32-e86e-41a9-a74c-dfae58264cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score com o dataset de treino: 0.98\n",
      "Score com o dataset de teste: 0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.42232109, 0.57767891])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repetindo o processo com alguns dos argumentos apresentados.\n",
    "# Agora, o modelo perdeu o seu vício com o dataset de treino.\n",
    "clf = DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 4).fit(X_train, y_train)\n",
    "print(f'Score com o dataset de treino: {clf.score(X_train, y_train):.2f}')\n",
    "print(f'Score com o dataset de teste: {clf.score(X_test, y_test):.2f}')\n",
    "\n",
    "# Os modelos de DecisionTrees possuem o atributo feature_importances_, que mostra o grau de relevância de cada característica das\n",
    "# instâncias para a sua segregação.\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849fb4b8-b3ae-44ea-a7c2-1d098cb7267c",
   "metadata": {},
   "source": [
    "<div>   \n",
    "    <center>\n",
    "        \n",
    "        <h1 style='font-size:30px'>Prós e Contras de Decision Trees</h1>\n",
    "        <img src='trees3.png'>\n",
    "        \n",
    "    </center>    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
