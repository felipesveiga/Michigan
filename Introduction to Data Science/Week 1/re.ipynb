{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd134b6-33ea-4d5e-8d28-ea34400cbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b87da0-87c0-4565-b5fc-20aa63a21e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good 2\n"
     ]
    }
   ],
   "source": [
    "# match() procura por correspondências do seu padrão no começo da string e retorna um valor booleano.\n",
    "# search() procura por correspondência em todo o texto e retorna um valor booleano.\n",
    "\n",
    "s = 'Hoje é terça-feira'\n",
    "pattern = 'terça'\n",
    "\n",
    "if re.match(pattern, s): # Não há 'terça no início da string'.\n",
    "    print('Good 1')\n",
    "    \n",
    "if re.search(pattern, s): # Há 'terça' em um trecho da string.\n",
    "    print('Good 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5655c1a4-29d4-4559-8017-94947c357ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' acorda; ', ' estuda; ', ' come; ', ' dorme']\n",
      "['Felipe', 'Felipe', 'Felipe', 'Felipe']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Podemos também realizar o processo de tokenizing, responsável por quebrar uma string em fragmentos.\n",
    "\n",
    "s = 'Felipe acorda; Felipe estuda; Felipe come; Felipe dorme'\n",
    "pattern = 'Felipe'\n",
    "\n",
    "# Note que split nos dará fragmentos de nossa string original em que o objeto pattern é removido\n",
    "print(re.split(pattern, s)) \n",
    "\n",
    "# findall nos dá uma lista com as ocorrências de nosso pattern\n",
    "print(re.findall(pattern, s)) \n",
    "\n",
    "# Poderíamos pedir ao Python o número de tais ocorrências\n",
    "print(len(re.findall(pattern, s))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab6ba09a-4a05-41ec-86aa-139b0371867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "não 1\n",
      "sim 2\n"
     ]
    }
   ],
   "source": [
    "# Vamos aprender alguns sinais bastante úteis em regular expressions\n",
    "\n",
    "# ^ indica que o que procuramos deve estar no início da string (isso inutiliza o método match)\n",
    "# $ indica que o padrão deve estar no final da string\n",
    "\n",
    "\n",
    "supermercado = 'Spagetti, Frango, Arroz, Batata, Alface, Feijão'\n",
    "\n",
    "# O primeiro item da lista é batata?\n",
    "if re.search('^Batata', supermercado):\n",
    "    print('sim 1')\n",
    "else:\n",
    "    print('não 1')\n",
    "    \n",
    "# Nossa lista termina com Feijão?\n",
    "if re.search('Feijão$', supermercado):\n",
    "    print('sim 2')\n",
    "    \n",
    "else:\n",
    "    print('não 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "279b3231-d265-40a6-9da0-78df39ea0571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# Vamos fazer algo mais complexo: Quantas lojas a Starbucks tem em São Paulo?\n",
    "import pandas as pd\n",
    "starbucks = pd.read_csv('directory.csv')\n",
    "\n",
    "count = 0\n",
    "for city in starbucks['City']:\n",
    "    city = str(city)\n",
    "    if re.search('Sao Paulo', city):\n",
    "        count += 1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "214e8cd6-88bf-4b03-9e1c-6db6899e9764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AB', 'AB']\n",
      "['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "grades = 'ABACBACBABCCA'\n",
    "\n",
    "# Procurando um A seguido imediatamente de um B em 'grades'\n",
    "print(re.findall('AB', grades)) \n",
    "\n",
    "# Procurando um A ou um B em grades\n",
    "print(re.findall('[AB]', grades)) \n",
    "\n",
    "# Note,os colchetes indicam um agrupamento de caracteres; estamos querendo procurar qualquer caractere dentro do grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ef986b81-793c-43fb-9a38-435290913266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11-99801-2131', '17-98121-3287', '19-91908-2134']\n",
      "['11-99801-2131', '21-99871-1231', '17-98121-3287', '21-89105-7591', '19-91908-2134', '24-28542-9090']\n",
      "['11', '21-99871-1231', '21-89105-7591']\n"
     ]
    }
   ],
   "source": [
    "# Você sabia que todos os DDD's do estado de São Paulo estão no intervalo [10, 19]?\n",
    "# Poderíamos utilizar esse padrão para identificar os números de celular do estado de SP\n",
    "\n",
    "telefones = ''' 11-99801-2131\n",
    "                21-99871-1231\n",
    "                17-98121-3287\n",
    "                34-21319-5673\n",
    "                57-65490-0909\n",
    "                21-89105-7591\n",
    "                19-91908-2134\n",
    "                24-28542-9090'''\n",
    "\n",
    "# Vamos selecionar apenas os números de telefone pertencentes a SP\n",
    "print(re.findall('1[0-9]-[0-9]{5}-[1-9]{4}', telefones))\n",
    "\n",
    "# Os DDD's do Rio de Janeiro começam com 2: vamos procurá-los também!\n",
    "print(re.findall('[12][0-9]-[0-9]{5}-[0-9]{4}', telefones)) \n",
    "\n",
    "# Agora temos os números de SP e do Rio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "42d4761e-d090-4486-8c0c-98977f704fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['João', 'João', 'Luís']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos procurar apenas os nomes João e Luís em 'clientes'\n",
    "# Vamos utilizar o pipe (|), equivalente a um OR nas linguagens de programação\n",
    "\n",
    "clientes = 'João Santos, Cléber Ferreira,  João Amoreira, Luís Ulian, Lúcio Igor, Heleno Augusto,'\n",
    "re.findall(r'João|Luís', clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eae40db9-8a86-400c-8ad8-4721e35503be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'B']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AA', 'AA']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nós já chegamos a mencionar o uso do circunflexo. Ele é responsável por indicar que o padrão procurado está\n",
    "# no início da string.\n",
    "\n",
    "# No entanto, caso esteja dentro de um agrupamento [], ele indicará a negação da string padrão\n",
    "grades = 'AABABACBAAABCC'\n",
    "\n",
    "# Poderíamos procurar todas as notas que não são C\n",
    "print(re.findall('[^C]', grades)) \n",
    "\n",
    "# Os diferentes usos de ^ podem ser um tanto confusos\n",
    "# Aqui, queremos verificar se o primeiro item de 'grades' é qualquer nota diferente de A\n",
    "\n",
    "# Isso é evidentemente falso pela lista vazia...\n",
    "re.findall('ˆ[^A]', grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c3f0d512-32fc-4697-ac34-743097139f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AA', 'AAA']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos pegar os casos em que nosso estudante tirou A's consecutivos\n",
    "# Como o comprimento de 'grades' é 14, vamos colocar esse número como limite do range\n",
    "print(len(grades))\n",
    "re.findall('A{2,14}', grades)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea0fc5-f427-4eb8-96f9-84391c097ad3",
   "metadata": {},
   "source": [
    "### Símbolos Quantitativos\n",
    "\\* (zero ou mais)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ba0be-5505-4595-b86e-f8f4922af764",
   "metadata": {},
   "source": [
    "\\+ (um ou mais)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d96447-5ad3-48f5-8827-20747e2d2240",
   "metadata": {},
   "source": [
    "\\? (zero ou 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7176f342-abf9-4d10-b500-8dfec278920c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overview[edit]', 'records[edit]', 'records[edit]']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ferpa.txt', 'r') as wiki_file:\n",
    "    wiki = wiki_file.read()\n",
    "    \n",
    "# Vamos escanear os títulos e subtítulos desse arquivo\n",
    "# Eles são compostos pelo nome do título seguido de '[edit]'\n",
    "\n",
    "# Usando o contrabarra pois os brackets são símbolos utilizados em regex, e queremos que o Python os interprete \n",
    "                                                                                            # de maneira literal.\n",
    "\n",
    "# Note, no entanto, que nosso código nos retorna apenas a última palavra do título!   \n",
    "re.findall('\\w*\\[edit\\]', wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa04fa96-c062-453d-b835-a90b8567e6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overview[edit]',\n",
       " 'Access to public records[edit]',\n",
       " 'Student medical records[edit]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos utilizar as special sequences\n",
    "re.findall(r'[\\w ]*\\[edit\\]', wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9252bd2-07b5-4b3e-b2af-a27b0ba0302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References\n",
      "External links\n"
     ]
    }
   ],
   "source": [
    "# Conseguimos o que queríamos. Mas poderíamos refinar a nossa busca com o processo de agrupamento ()\n",
    "# Podemos definir categorias de outputs desejados dentro da definição de nosso padrão buscado\n",
    "\n",
    "# O Python agrupará os resultados conforme o seu respectivo grupo\n",
    "\n",
    "# Para a nossa busca pelos títulos do artigo, definimos dois padrões desejados. Um para termos que tiverem \n",
    "# vários caracteres ou espaços; outro para os casos do [edit]\n",
    "re.findall('([\\w ]*)(\\[edit\\])', wiki)\n",
    "\n",
    "# Portanto, pode-se enxergar que conseguimos filtrar as informações necessárias daquela desnecessária\n",
    "\n",
    "# Iterando sobre o nosso novo findall e printando apenas os nomes dos títulos:\n",
    "for title in re.findall('([\\w ]*)(\\[edit\\])', wiki):\n",
    "    print(title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bd69bd0-2043-468c-b455-8ac6a7735702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview\n",
      "Access to public records\n",
      "Student medical records\n"
     ]
    }
   ],
   "source": [
    "# Podemos tabmém criar um objeto iterador sobre os padrões desejados\n",
    "\n",
    "for item in re.finditer('([\\w ]*)(\\[edit\\])', wiki):\n",
    "    print(item.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a7eed0e-145f-4c5f-b7d7-6a9fdbfaf1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview\n",
      "Access to public records\n",
      "Student medical records\n"
     ]
    }
   ],
   "source": [
    "# Podemos também criar um dicionário para cada padrão encontrado\n",
    "\n",
    "pattern = '(?P<title>[\\w ]+)(?P<edit>\\[edit\\])'\n",
    "for item in re.finditer(pattern, wiki):\n",
    "    print(item.groupdict()['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d45b81a4-834d-4668-9a7b-50a2fcf0db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos pegar um documento que discute sobre as universidades budistas nos EUA\n",
    "# Podemos verificar que o nome das universidades é seguido por um dash e o nome da sua cidade e estado\n",
    "with open('buddhist.txt', 'r') as file:\n",
    "    wiki = file.read()\n",
    "    \n",
    "pattern=\"\"\"\n",
    "(?P<title>.*) #ofwe\n",
    "(-\\ located\\ in\\ ) #osnfwe\n",
    "(?P<city>\\w*) #igoiwen\n",
    "(,\\ ) #oisenioew\n",
    "(?P<state>\\w*) #sgnioenge \"\"\"\n",
    "\n",
    "pattern=\"\"\"\n",
    "(?P<title>.*)        #the university title\n",
    "(–\\ located\\ in\\ )   #an indicator of the location\n",
    "(?P<city>\\w*)        #city the university is in\n",
    "(,\\ )                #separator for the state\n",
    "(?P<state>\\w*)       #the state the city is located in\"\"\"\n",
    "\n",
    "for item in re.finditer(pattern, wiki, re.VERBOSE):\n",
    "    print(item.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a7ec2cc6-598b-4aa7-bc5b-7594fd1ed550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Dhammakaya Open University ', 'city': 'Azusa', 'state': 'California'}\n",
      "{'title': 'Dharmakirti College ', 'city': 'Tucson', 'state': 'Arizona'}\n",
      "{'title': 'Dharma Realm Buddhist University ', 'city': 'Ukiah', 'state': 'California'}\n",
      "{'title': 'Ewam Buddhist Institute ', 'city': 'Arlee', 'state': 'Montana'}\n",
      "{'title': 'Institute of Buddhist Studies ', 'city': 'Berkeley', 'state': 'California'}\n",
      "{'title': 'Maitripa College ', 'city': 'Portland', 'state': 'Oregon'}\n",
      "{'title': 'University of the West ', 'city': 'Rosemead', 'state': 'California'}\n",
      "{'title': 'Won Institute of Graduate Studies ', 'city': 'Glenside', 'state': 'Pennsylvania'}\n"
     ]
    }
   ],
   "source": [
    "with open('buddhist.txt', 'r') as file:\n",
    "    wiki = file.read()\n",
    "    \n",
    "pattern=\"\"\"\n",
    "(?P<title>.*)\n",
    "(–\\ located\\ in\\ )\n",
    "(?P<city>\\w*) #igoiwen\n",
    "(,\\ ) #oisenioew\n",
    "(?P<state>\\w*)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for item in re.finditer(pattern, wiki, re.VERBOSE):\n",
    "    print(item.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94505e3d-2823-4317-9d7a-06d9105aeaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#askwell ',\n",
       " '#pregnancy ',\n",
       " '#VegetarianThanksgiving ',\n",
       " '#FallPrevention ',\n",
       " '#Ebola ',\n",
       " '#ebola ',\n",
       " '#Ebola ',\n",
       " '#Ebola ',\n",
       " '#EbolaHysteria ',\n",
       " '#AskNYT ',\n",
       " '#Ebola ',\n",
       " '#Ebola ',\n",
       " '#Liberia ',\n",
       " '#Excalibur ',\n",
       " '#ebola ',\n",
       " '#Ebola ',\n",
       " '#dallas ',\n",
       " '#nobelprize2014 ',\n",
       " '#ebola ',\n",
       " '#ebola ',\n",
       " '#monrovia ',\n",
       " '#ebola ',\n",
       " '#nobelprize2014 ',\n",
       " '#ebola ',\n",
       " '#nobelprize2014 ',\n",
       " '#Medicine ',\n",
       " '#Ebola ',\n",
       " '#Monrovia ',\n",
       " '#Ebola ',\n",
       " '#smell ',\n",
       " '#Ebola ',\n",
       " '#Ebola ',\n",
       " '#Ebola ',\n",
       " '#Monrovia ',\n",
       " '#Ebola ',\n",
       " '#ebola ',\n",
       " '#monrovia ',\n",
       " '#liberia ',\n",
       " '#benzos ',\n",
       " '#ClimateChange ',\n",
       " '#Whole ',\n",
       " '#Wheat ',\n",
       " '#Focaccia ',\n",
       " '#Tomatoes ',\n",
       " '#Olives ',\n",
       " '#Recipes ',\n",
       " '#Ebola ',\n",
       " '#Monrovia ',\n",
       " '#Liberia ',\n",
       " '#Ebola ',\n",
       " '#Ebola ',\n",
       " '#Liberia ',\n",
       " '#Ebola ',\n",
       " '#blood ',\n",
       " '#Ebola ',\n",
       " '#EbolaOutbreak ',\n",
       " '#SierraLeone ',\n",
       " '#Freetown ',\n",
       " '#SierraLeone ',\n",
       " '#ebolaoutbreak ',\n",
       " '#kenema ',\n",
       " '#ebola ',\n",
       " '#Ebola ',\n",
       " '#ebola ',\n",
       " '#ebola ',\n",
       " '#Ebola ',\n",
       " '#AIDS2014 ',\n",
       " '#AIDS ',\n",
       " '#MH17 ',\n",
       " '#benzos ']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('nytimeshealth.txt', 'r') as file:\n",
    "    wiki = file.read()\n",
    "    \n",
    "pattern = '\\#\\w* '\n",
    "re.findall(pattern, wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d52e4721-6e29-4332-b6f6-8b221b18b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.aBC.com', 'abc.com', 'ab_c.de8f.com']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "www = '''www.aBC.com, abc.com, ab_c.de8f.com'''\n",
    "pattern = 'w*\\.?[\\w_.]+\\.com'\n",
    "re.findall(pattern,www)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a3771c6-5eb6-4a8e-9c6c-19885d3035ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'abc', 'abc', 'abc']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'abcbacbabbabcabcabccaacb'\n",
    "pattern = 'abc'\n",
    "re.findall(pattern, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "481cfe57-6bc7-41d6-b665-b851ce625ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok1 = 'unicorn'\n",
    "ok2 = 'element'\n",
    "not_ok1 = 'banana'\n",
    "not_ok2 = 'apple'\n",
    "\n",
    "pattern = '^[a|e|i|o|u]\\w*[^a|e|i|o|u]$'\n",
    "\n",
    "re.findall(pattern, not_ok1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1764745d-c78f-443a-9393-a06f6f7a807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0xf3', '0x1d', '0x072']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '0[o|x][0-7|0-9|a-f]+'\n",
    "ok1 = '0o117'\n",
    "ok2 = '0xf3'\n",
    "\n",
    "ok3 = '0xf3, 0x1d, 0x072'\n",
    "not1 = '1233'\n",
    "not2 = '0o12f'\n",
    "\n",
    "re.findall(pattern,ok3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f5892303-fe8b-4319-8a77-928b2b563294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L Zhang']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '^[A-Z][a-z]* [A-Z][a-z]*'\n",
    "ok1 = 'Jane Doe is eating breakfast.'\n",
    "ok2 = 'Zhang is a great Broadway actor.'\n",
    "ok3 = 'Issac Newton'\n",
    "ok4 = 'L Zhang'\n",
    "re.findall(pattern, ok4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
